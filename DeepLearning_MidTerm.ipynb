{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjB2ixrsVe+wCYYgny8Rn2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slachitoff/CS-GY-6613-Assignments/blob/main/DeepLearning_MidTerm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "\n",
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "def load_cifar10_batch(batch_filename):\n",
        "    batch = unpickle(batch_filename)\n",
        "    images = batch[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "    labels = batch[b'labels']\n",
        "    return images, labels\n",
        "\n",
        "train_images1, train_labels1 = load_cifar10_batch('/content/data_batch_1')\n",
        "train_images2, train_labels2 = load_cifar10_batch('/content/data_batch_2')\n",
        "train_images3, train_labels3 = load_cifar10_batch('/content/data_batch_3')\n",
        "train_images4, train_labels4 = load_cifar10_batch('/content/data_batch_4')\n",
        "train_images5, train_labels5 = load_cifar10_batch('/content/data_batch_5')\n",
        "\n",
        "original_train_images = np.concatenate((train_images1, train_images2, train_images3, train_images4, train_images5))\n",
        "original_train_labels = np.concatenate((train_labels1, train_labels2, train_labels3, train_labels4, train_labels5))\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    ToPILImage(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    ToPILImage(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "num_train = int(0.95 * len(original_train_images))\n",
        "num_val = len(original_train_images) - num_train\n",
        "\n",
        "shuffled_indices = np.random.permutation(len(original_train_images))\n",
        "\n",
        "train_idx = shuffled_indices[:num_train]\n",
        "val_idx = shuffled_indices[num_train:]\n",
        "\n",
        "train_images_subset = original_train_images[train_idx]\n",
        "val_images_subset = original_train_images[val_idx]\n",
        "train_labels_subset = original_train_labels[train_idx]\n",
        "val_labels_subset = original_train_labels[val_idx]\n",
        "\n",
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.images[index], self.labels[index]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "BATCH_SIZE_TRAIN = 128\n",
        "BATCH_SIZE_TEST = 100\n",
        "\n",
        "train_dataset = CIFAR10Dataset(train_images_subset, train_labels_subset, transform=transform_train)\n",
        "val_dataset = CIFAR10Dataset(val_images_subset, val_labels_subset, transform=transform_test)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "Doqa4nsFnj3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "qxv73o26-ujU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, dropout_rate=0.5):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "        self.dropout_final = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.dropout1(out)\n",
        "\n",
        "        out = self.layer2(out)\n",
        "        out = self.dropout2(out)\n",
        "\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        out = self.dropout_final(out)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "9YZgaVWFAqJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNet(BasicBlock, [2, 1, 1, 1], num_classes=10, dropout_rate=0.4)\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "CumoAyjOQKri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d03dc6-05ab-43cc-9f1a-a8654826eb61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (dropout1): Dropout(p=0.4, inplace=False)\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout2): Dropout(p=0.4, inplace=False)\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (dropout_final): Dropout(p=0.4, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "id": "qaKgRs_mOK_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b133129-2ea7-4eff-831d-da86ea1b97f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "          Dropout-13           [-1, 64, 32, 32]               0\n",
            "           Conv2d-14          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-15          [-1, 128, 16, 16]             256\n",
            "           Conv2d-16          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-17          [-1, 128, 16, 16]             256\n",
            "           Conv2d-18          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-19          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-20          [-1, 128, 16, 16]               0\n",
            "          Dropout-21          [-1, 128, 16, 16]               0\n",
            "           Conv2d-22            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-23            [-1, 256, 8, 8]             512\n",
            "           Conv2d-24            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-25            [-1, 256, 8, 8]             512\n",
            "           Conv2d-26            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-27            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-28            [-1, 256, 8, 8]               0\n",
            "           Conv2d-29            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-30            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-33            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-34            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-35            [-1, 512, 4, 4]               0\n",
            "          Dropout-36                  [-1, 512]               0\n",
            "           Linear-37                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 4,977,226\n",
            "Trainable params: 4,977,226\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 9.82\n",
            "Params size (MB): 18.99\n",
            "Estimated Total Size (MB): 28.81\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def train_epoch(model, optimizer, scheduler, data_loader, criterion, device, loss_history):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for data, target in data_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    print(f'Training: Average Loss: {avg_loss:.4f}, Accuracy: {correct}/{total} ({accuracy:.0f}%)')\n",
        "    loss_history.append(avg_loss)\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def validate(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            val_loss += criterion(output, target).item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    avg_loss = val_loss / len(data_loader)\n",
        "    accuracy = 100. * correct / len(data_loader.dataset)\n",
        "    print(f'Validation: Average Loss: {avg_loss:.4f}, Accuracy: {correct}/{len(data_loader.dataset)} ({accuracy:.0f}%)')\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "N_EPOCHS = 200\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.002, weight_decay=0.02)\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=N_EPOCHS)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start_time = time.time()\n",
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "val_loss_history = []\n",
        "val_accuracy_history = []\n",
        "\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "    print(f'\\nEpoch {epoch}/{N_EPOCHS}')\n",
        "    train_avg_loss, train_accuracy = train_epoch(model, optimizer, scheduler, train_loader, criterion, device, train_loss_history)\n",
        "    train_accuracy_history.append(train_accuracy)\n",
        "\n",
        "    val_avg_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
        "    val_loss_history.append(val_avg_loss)\n",
        "    val_accuracy_history.append(val_accuracy)\n",
        "\n",
        "execution_time = time.time() - start_time\n",
        "print(f'\\nExecution time: {execution_time:.2f} seconds')"
      ],
      "metadata": {
        "id": "BJAINMaPAbeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d14841f-7f61-476a-8ace-2696f3b0893d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/200\n",
            "Training: Average Loss: 1.6801, Accuracy: 17456/47500 (37%)\n",
            "Validation: Average Loss: 1.4920, Accuracy: 1148/2500 (46%)\n",
            "\n",
            "Epoch 2/200\n",
            "Training: Average Loss: 1.3651, Accuracy: 23783/47500 (50%)\n",
            "Validation: Average Loss: 1.2957, Accuracy: 1343/2500 (54%)\n",
            "\n",
            "Epoch 3/200\n",
            "Training: Average Loss: 1.2079, Accuracy: 26836/47500 (56%)\n",
            "Validation: Average Loss: 1.1825, Accuracy: 1449/2500 (58%)\n",
            "\n",
            "Epoch 4/200\n",
            "Training: Average Loss: 1.1203, Accuracy: 28502/47500 (60%)\n",
            "Validation: Average Loss: 1.1261, Accuracy: 1509/2500 (60%)\n",
            "\n",
            "Epoch 5/200\n",
            "Training: Average Loss: 1.0424, Accuracy: 29900/47500 (63%)\n",
            "Validation: Average Loss: 1.1852, Accuracy: 1532/2500 (61%)\n",
            "\n",
            "Epoch 6/200\n",
            "Training: Average Loss: 0.9998, Accuracy: 30545/47500 (64%)\n",
            "Validation: Average Loss: 1.0419, Accuracy: 1591/2500 (64%)\n",
            "\n",
            "Epoch 7/200\n",
            "Training: Average Loss: 0.9548, Accuracy: 31369/47500 (66%)\n",
            "Validation: Average Loss: 0.9852, Accuracy: 1686/2500 (67%)\n",
            "\n",
            "Epoch 8/200\n",
            "Training: Average Loss: 0.9241, Accuracy: 31829/47500 (67%)\n",
            "Validation: Average Loss: 0.9270, Accuracy: 1724/2500 (69%)\n",
            "\n",
            "Epoch 9/200\n",
            "Training: Average Loss: 0.8911, Accuracy: 32508/47500 (68%)\n",
            "Validation: Average Loss: 1.0958, Accuracy: 1632/2500 (65%)\n",
            "\n",
            "Epoch 10/200\n",
            "Training: Average Loss: 0.8664, Accuracy: 32903/47500 (69%)\n",
            "Validation: Average Loss: 0.8420, Accuracy: 1776/2500 (71%)\n",
            "\n",
            "Epoch 11/200\n",
            "Training: Average Loss: 0.8410, Accuracy: 33248/47500 (70%)\n",
            "Validation: Average Loss: 0.7871, Accuracy: 1824/2500 (73%)\n",
            "\n",
            "Epoch 12/200\n",
            "Training: Average Loss: 0.8151, Accuracy: 33809/47500 (71%)\n",
            "Validation: Average Loss: 0.7429, Accuracy: 1864/2500 (75%)\n",
            "\n",
            "Epoch 13/200\n",
            "Training: Average Loss: 0.7966, Accuracy: 34168/47500 (72%)\n",
            "Validation: Average Loss: 0.7769, Accuracy: 1846/2500 (74%)\n",
            "\n",
            "Epoch 14/200\n",
            "Training: Average Loss: 0.7660, Accuracy: 34709/47500 (73%)\n",
            "Validation: Average Loss: 0.8416, Accuracy: 1781/2500 (71%)\n",
            "\n",
            "Epoch 15/200\n",
            "Training: Average Loss: 0.7460, Accuracy: 34995/47500 (74%)\n",
            "Validation: Average Loss: 0.7340, Accuracy: 1883/2500 (75%)\n",
            "\n",
            "Epoch 16/200\n",
            "Training: Average Loss: 0.7273, Accuracy: 35283/47500 (74%)\n",
            "Validation: Average Loss: 0.6601, Accuracy: 1944/2500 (78%)\n",
            "\n",
            "Epoch 17/200\n",
            "Training: Average Loss: 0.6988, Accuracy: 35891/47500 (76%)\n",
            "Validation: Average Loss: 0.6663, Accuracy: 1923/2500 (77%)\n",
            "\n",
            "Epoch 18/200\n",
            "Training: Average Loss: 0.6907, Accuracy: 35882/47500 (76%)\n",
            "Validation: Average Loss: 0.6364, Accuracy: 1940/2500 (78%)\n",
            "\n",
            "Epoch 19/200\n",
            "Training: Average Loss: 0.6700, Accuracy: 36287/47500 (76%)\n",
            "Validation: Average Loss: 0.7600, Accuracy: 1869/2500 (75%)\n",
            "\n",
            "Epoch 20/200\n",
            "Training: Average Loss: 0.6581, Accuracy: 36466/47500 (77%)\n",
            "Validation: Average Loss: 0.6565, Accuracy: 1934/2500 (77%)\n",
            "\n",
            "Epoch 21/200\n",
            "Training: Average Loss: 0.6451, Accuracy: 36804/47500 (77%)\n",
            "Validation: Average Loss: 0.6329, Accuracy: 1974/2500 (79%)\n",
            "\n",
            "Epoch 22/200\n",
            "Training: Average Loss: 0.6309, Accuracy: 36946/47500 (78%)\n",
            "Validation: Average Loss: 0.6746, Accuracy: 1933/2500 (77%)\n",
            "\n",
            "Epoch 23/200\n",
            "Training: Average Loss: 0.6298, Accuracy: 37036/47500 (78%)\n",
            "Validation: Average Loss: 0.6583, Accuracy: 1945/2500 (78%)\n",
            "\n",
            "Epoch 24/200\n",
            "Training: Average Loss: 0.6194, Accuracy: 37240/47500 (78%)\n",
            "Validation: Average Loss: 0.6383, Accuracy: 1953/2500 (78%)\n",
            "\n",
            "Epoch 25/200\n",
            "Training: Average Loss: 0.6139, Accuracy: 37359/47500 (79%)\n",
            "Validation: Average Loss: 0.5748, Accuracy: 2027/2500 (81%)\n",
            "\n",
            "Epoch 26/200\n",
            "Training: Average Loss: 0.5986, Accuracy: 37590/47500 (79%)\n",
            "Validation: Average Loss: 0.5609, Accuracy: 2012/2500 (80%)\n",
            "\n",
            "Epoch 27/200\n",
            "Training: Average Loss: 0.5938, Accuracy: 37664/47500 (79%)\n",
            "Validation: Average Loss: 0.5324, Accuracy: 2049/2500 (82%)\n",
            "\n",
            "Epoch 28/200\n",
            "Training: Average Loss: 0.5853, Accuracy: 37711/47500 (79%)\n",
            "Validation: Average Loss: 0.5215, Accuracy: 2044/2500 (82%)\n",
            "\n",
            "Epoch 29/200\n",
            "Training: Average Loss: 0.5770, Accuracy: 38008/47500 (80%)\n",
            "Validation: Average Loss: 0.6078, Accuracy: 1987/2500 (79%)\n",
            "\n",
            "Epoch 30/200\n",
            "Training: Average Loss: 0.5769, Accuracy: 37910/47500 (80%)\n",
            "Validation: Average Loss: 0.5990, Accuracy: 1982/2500 (79%)\n",
            "\n",
            "Epoch 31/200\n",
            "Training: Average Loss: 0.5720, Accuracy: 38124/47500 (80%)\n",
            "Validation: Average Loss: 0.6658, Accuracy: 1961/2500 (78%)\n",
            "\n",
            "Epoch 32/200\n",
            "Training: Average Loss: 0.5644, Accuracy: 38236/47500 (80%)\n",
            "Validation: Average Loss: 0.5388, Accuracy: 2037/2500 (81%)\n",
            "\n",
            "Epoch 33/200\n",
            "Training: Average Loss: 0.5653, Accuracy: 38172/47500 (80%)\n",
            "Validation: Average Loss: 0.5616, Accuracy: 2016/2500 (81%)\n",
            "\n",
            "Epoch 34/200\n",
            "Training: Average Loss: 0.5660, Accuracy: 38155/47500 (80%)\n",
            "Validation: Average Loss: 0.5599, Accuracy: 2044/2500 (82%)\n",
            "\n",
            "Epoch 35/200\n",
            "Training: Average Loss: 0.5558, Accuracy: 38294/47500 (81%)\n",
            "Validation: Average Loss: 0.7314, Accuracy: 1897/2500 (76%)\n",
            "\n",
            "Epoch 36/200\n",
            "Training: Average Loss: 0.5567, Accuracy: 38296/47500 (81%)\n",
            "Validation: Average Loss: 0.5689, Accuracy: 2012/2500 (80%)\n",
            "\n",
            "Epoch 37/200\n",
            "Training: Average Loss: 0.5614, Accuracy: 38256/47500 (81%)\n",
            "Validation: Average Loss: 0.7638, Accuracy: 1887/2500 (75%)\n",
            "\n",
            "Epoch 38/200\n",
            "Training: Average Loss: 0.5476, Accuracy: 38440/47500 (81%)\n",
            "Validation: Average Loss: 1.0192, Accuracy: 1820/2500 (73%)\n",
            "\n",
            "Epoch 39/200\n",
            "Training: Average Loss: 0.5709, Accuracy: 38118/47500 (80%)\n",
            "Validation: Average Loss: 0.5686, Accuracy: 2042/2500 (82%)\n",
            "\n",
            "Epoch 40/200\n",
            "Training: Average Loss: 0.5482, Accuracy: 38444/47500 (81%)\n",
            "Validation: Average Loss: 0.6159, Accuracy: 1999/2500 (80%)\n",
            "\n",
            "Epoch 41/200\n",
            "Training: Average Loss: 0.5577, Accuracy: 38327/47500 (81%)\n",
            "Validation: Average Loss: 0.5031, Accuracy: 2070/2500 (83%)\n",
            "\n",
            "Epoch 42/200\n",
            "Training: Average Loss: 0.5462, Accuracy: 38436/47500 (81%)\n",
            "Validation: Average Loss: 0.5523, Accuracy: 2048/2500 (82%)\n",
            "\n",
            "Epoch 43/200\n",
            "Training: Average Loss: 0.5459, Accuracy: 38531/47500 (81%)\n",
            "Validation: Average Loss: 0.5149, Accuracy: 2078/2500 (83%)\n",
            "\n",
            "Epoch 44/200\n",
            "Training: Average Loss: 0.5424, Accuracy: 38566/47500 (81%)\n",
            "Validation: Average Loss: 0.5083, Accuracy: 2088/2500 (84%)\n",
            "\n",
            "Epoch 45/200\n",
            "Training: Average Loss: 0.5473, Accuracy: 38476/47500 (81%)\n",
            "Validation: Average Loss: 0.5319, Accuracy: 2081/2500 (83%)\n",
            "\n",
            "Epoch 46/200\n",
            "Training: Average Loss: 0.5533, Accuracy: 38392/47500 (81%)\n",
            "Validation: Average Loss: 0.6121, Accuracy: 2012/2500 (80%)\n",
            "\n",
            "Epoch 47/200\n",
            "Training: Average Loss: 0.5448, Accuracy: 38473/47500 (81%)\n",
            "Validation: Average Loss: 0.5834, Accuracy: 2012/2500 (80%)\n",
            "\n",
            "Epoch 48/200\n",
            "Training: Average Loss: 0.5387, Accuracy: 38602/47500 (81%)\n",
            "Validation: Average Loss: 0.7686, Accuracy: 1909/2500 (76%)\n",
            "\n",
            "Epoch 49/200\n",
            "Training: Average Loss: 0.5380, Accuracy: 38658/47500 (81%)\n",
            "Validation: Average Loss: 0.5672, Accuracy: 2021/2500 (81%)\n",
            "\n",
            "Epoch 50/200\n",
            "Training: Average Loss: 0.5411, Accuracy: 38556/47500 (81%)\n",
            "Validation: Average Loss: 0.9222, Accuracy: 1805/2500 (72%)\n",
            "\n",
            "Epoch 51/200\n",
            "Training: Average Loss: 0.5426, Accuracy: 38537/47500 (81%)\n",
            "Validation: Average Loss: 0.5175, Accuracy: 2060/2500 (82%)\n",
            "\n",
            "Epoch 52/200\n",
            "Training: Average Loss: 0.5358, Accuracy: 38660/47500 (81%)\n",
            "Validation: Average Loss: 0.6578, Accuracy: 1964/2500 (79%)\n",
            "\n",
            "Epoch 53/200\n",
            "Training: Average Loss: 0.5405, Accuracy: 38637/47500 (81%)\n",
            "Validation: Average Loss: 0.5288, Accuracy: 2059/2500 (82%)\n",
            "\n",
            "Epoch 54/200\n",
            "Training: Average Loss: 0.5337, Accuracy: 38720/47500 (82%)\n",
            "Validation: Average Loss: 0.4837, Accuracy: 2082/2500 (83%)\n",
            "\n",
            "Epoch 55/200\n",
            "Training: Average Loss: 0.5324, Accuracy: 38736/47500 (82%)\n",
            "Validation: Average Loss: 0.5609, Accuracy: 2030/2500 (81%)\n",
            "\n",
            "Epoch 56/200\n",
            "Training: Average Loss: 0.5341, Accuracy: 38805/47500 (82%)\n",
            "Validation: Average Loss: 0.5954, Accuracy: 2032/2500 (81%)\n",
            "\n",
            "Epoch 57/200\n",
            "Training: Average Loss: 0.5349, Accuracy: 38673/47500 (81%)\n",
            "Validation: Average Loss: 0.6333, Accuracy: 1985/2500 (79%)\n",
            "\n",
            "Epoch 58/200\n",
            "Training: Average Loss: 0.5372, Accuracy: 38653/47500 (81%)\n",
            "Validation: Average Loss: 0.5441, Accuracy: 2044/2500 (82%)\n",
            "\n",
            "Epoch 59/200\n",
            "Training: Average Loss: 0.5201, Accuracy: 38969/47500 (82%)\n",
            "Validation: Average Loss: 0.5771, Accuracy: 2020/2500 (81%)\n",
            "\n",
            "Epoch 60/200\n",
            "Training: Average Loss: 0.5208, Accuracy: 38947/47500 (82%)\n",
            "Validation: Average Loss: 0.5589, Accuracy: 2028/2500 (81%)\n",
            "\n",
            "Epoch 61/200\n",
            "Training: Average Loss: 0.5290, Accuracy: 38829/47500 (82%)\n",
            "Validation: Average Loss: 0.5452, Accuracy: 2069/2500 (83%)\n",
            "\n",
            "Epoch 62/200\n",
            "Training: Average Loss: 0.5162, Accuracy: 38923/47500 (82%)\n",
            "Validation: Average Loss: 0.5836, Accuracy: 2023/2500 (81%)\n",
            "\n",
            "Epoch 63/200\n",
            "Training: Average Loss: 0.5083, Accuracy: 39083/47500 (82%)\n",
            "Validation: Average Loss: 0.5820, Accuracy: 2009/2500 (80%)\n",
            "\n",
            "Epoch 64/200\n",
            "Training: Average Loss: 0.5130, Accuracy: 39074/47500 (82%)\n",
            "Validation: Average Loss: 0.6613, Accuracy: 1984/2500 (79%)\n",
            "\n",
            "Epoch 65/200\n",
            "Training: Average Loss: 0.5230, Accuracy: 38971/47500 (82%)\n",
            "Validation: Average Loss: 0.8460, Accuracy: 1863/2500 (75%)\n",
            "\n",
            "Epoch 66/200\n",
            "Training: Average Loss: 0.5131, Accuracy: 39035/47500 (82%)\n",
            "Validation: Average Loss: 0.5072, Accuracy: 2091/2500 (84%)\n",
            "\n",
            "Epoch 67/200\n",
            "Training: Average Loss: 0.5024, Accuracy: 39176/47500 (82%)\n",
            "Validation: Average Loss: 0.6149, Accuracy: 1977/2500 (79%)\n",
            "\n",
            "Epoch 68/200\n",
            "Training: Average Loss: 0.5045, Accuracy: 39242/47500 (83%)\n",
            "Validation: Average Loss: 0.5713, Accuracy: 2049/2500 (82%)\n",
            "\n",
            "Epoch 69/200\n",
            "Training: Average Loss: 0.5083, Accuracy: 39228/47500 (83%)\n",
            "Validation: Average Loss: 0.5667, Accuracy: 2028/2500 (81%)\n",
            "\n",
            "Epoch 70/200\n",
            "Training: Average Loss: 0.4957, Accuracy: 39322/47500 (83%)\n",
            "Validation: Average Loss: 0.4502, Accuracy: 2120/2500 (85%)\n",
            "\n",
            "Epoch 71/200\n",
            "Training: Average Loss: 0.5057, Accuracy: 39322/47500 (83%)\n",
            "Validation: Average Loss: 0.5481, Accuracy: 2056/2500 (82%)\n",
            "\n",
            "Epoch 72/200\n",
            "Training: Average Loss: 0.5017, Accuracy: 39281/47500 (83%)\n",
            "Validation: Average Loss: 0.4649, Accuracy: 2115/2500 (85%)\n",
            "\n",
            "Epoch 73/200\n",
            "Training: Average Loss: 0.4895, Accuracy: 39519/47500 (83%)\n",
            "Validation: Average Loss: 0.5998, Accuracy: 2041/2500 (82%)\n",
            "\n",
            "Epoch 74/200\n",
            "Training: Average Loss: 0.4898, Accuracy: 39438/47500 (83%)\n",
            "Validation: Average Loss: 0.6431, Accuracy: 1986/2500 (79%)\n",
            "\n",
            "Epoch 75/200\n",
            "Training: Average Loss: 0.5011, Accuracy: 39254/47500 (83%)\n",
            "Validation: Average Loss: 0.4349, Accuracy: 2126/2500 (85%)\n",
            "\n",
            "Epoch 76/200\n",
            "Training: Average Loss: 0.4855, Accuracy: 39516/47500 (83%)\n",
            "Validation: Average Loss: 0.5182, Accuracy: 2071/2500 (83%)\n",
            "\n",
            "Epoch 77/200\n",
            "Training: Average Loss: 0.4825, Accuracy: 39505/47500 (83%)\n",
            "Validation: Average Loss: 0.4656, Accuracy: 2100/2500 (84%)\n",
            "\n",
            "Epoch 78/200\n",
            "Training: Average Loss: 0.4828, Accuracy: 39588/47500 (83%)\n",
            "Validation: Average Loss: 0.4953, Accuracy: 2080/2500 (83%)\n",
            "\n",
            "Epoch 79/200\n",
            "Training: Average Loss: 0.4813, Accuracy: 39613/47500 (83%)\n",
            "Validation: Average Loss: 0.6229, Accuracy: 2033/2500 (81%)\n",
            "\n",
            "Epoch 80/200\n",
            "Training: Average Loss: 0.4756, Accuracy: 39728/47500 (84%)\n",
            "Validation: Average Loss: 0.4727, Accuracy: 2115/2500 (85%)\n",
            "\n",
            "Epoch 81/200\n",
            "Training: Average Loss: 0.4820, Accuracy: 39625/47500 (83%)\n",
            "Validation: Average Loss: 0.6465, Accuracy: 2000/2500 (80%)\n",
            "\n",
            "Epoch 82/200\n",
            "Training: Average Loss: 0.4763, Accuracy: 39591/47500 (83%)\n",
            "Validation: Average Loss: 0.4660, Accuracy: 2123/2500 (85%)\n",
            "\n",
            "Epoch 83/200\n",
            "Training: Average Loss: 0.4685, Accuracy: 39815/47500 (84%)\n",
            "Validation: Average Loss: 0.4361, Accuracy: 2150/2500 (86%)\n",
            "\n",
            "Epoch 84/200\n",
            "Training: Average Loss: 0.4719, Accuracy: 39715/47500 (84%)\n",
            "Validation: Average Loss: 0.5499, Accuracy: 2051/2500 (82%)\n",
            "\n",
            "Epoch 85/200\n",
            "Training: Average Loss: 0.4760, Accuracy: 39733/47500 (84%)\n",
            "Validation: Average Loss: 0.4180, Accuracy: 2125/2500 (85%)\n",
            "\n",
            "Epoch 86/200\n",
            "Training: Average Loss: 0.4729, Accuracy: 39737/47500 (84%)\n",
            "Validation: Average Loss: 0.4600, Accuracy: 2124/2500 (85%)\n",
            "\n",
            "Epoch 87/200\n",
            "Training: Average Loss: 0.4600, Accuracy: 39930/47500 (84%)\n",
            "Validation: Average Loss: 0.4464, Accuracy: 2127/2500 (85%)\n",
            "\n",
            "Epoch 88/200\n",
            "Training: Average Loss: 0.4591, Accuracy: 39936/47500 (84%)\n",
            "Validation: Average Loss: 0.5017, Accuracy: 2086/2500 (83%)\n",
            "\n",
            "Epoch 89/200\n",
            "Training: Average Loss: 0.4576, Accuracy: 39998/47500 (84%)\n",
            "Validation: Average Loss: 0.5589, Accuracy: 2079/2500 (83%)\n",
            "\n",
            "Epoch 90/200\n",
            "Training: Average Loss: 0.4635, Accuracy: 39914/47500 (84%)\n",
            "Validation: Average Loss: 0.5511, Accuracy: 2051/2500 (82%)\n",
            "\n",
            "Epoch 91/200\n",
            "Training: Average Loss: 0.4726, Accuracy: 39745/47500 (84%)\n",
            "Validation: Average Loss: 0.5250, Accuracy: 2104/2500 (84%)\n",
            "\n",
            "Epoch 92/200\n",
            "Training: Average Loss: 0.4569, Accuracy: 39979/47500 (84%)\n",
            "Validation: Average Loss: 0.4541, Accuracy: 2119/2500 (85%)\n",
            "\n",
            "Epoch 93/200\n",
            "Training: Average Loss: 0.4506, Accuracy: 40070/47500 (84%)\n",
            "Validation: Average Loss: 0.5287, Accuracy: 2078/2500 (83%)\n",
            "\n",
            "Epoch 94/200\n",
            "Training: Average Loss: 0.4467, Accuracy: 40214/47500 (85%)\n",
            "Validation: Average Loss: 0.5625, Accuracy: 2083/2500 (83%)\n",
            "\n",
            "Epoch 95/200\n",
            "Training: Average Loss: 0.4572, Accuracy: 40042/47500 (84%)\n",
            "Validation: Average Loss: 0.4198, Accuracy: 2138/2500 (86%)\n",
            "\n",
            "Epoch 96/200\n",
            "Training: Average Loss: 0.4459, Accuracy: 40162/47500 (85%)\n",
            "Validation: Average Loss: 0.4802, Accuracy: 2106/2500 (84%)\n",
            "\n",
            "Epoch 97/200\n",
            "Training: Average Loss: 0.4395, Accuracy: 40289/47500 (85%)\n",
            "Validation: Average Loss: 0.5770, Accuracy: 2043/2500 (82%)\n",
            "\n",
            "Epoch 98/200\n",
            "Training: Average Loss: 0.4376, Accuracy: 40317/47500 (85%)\n",
            "Validation: Average Loss: 0.5382, Accuracy: 2066/2500 (83%)\n",
            "\n",
            "Epoch 99/200\n",
            "Training: Average Loss: 0.4332, Accuracy: 40381/47500 (85%)\n",
            "Validation: Average Loss: 0.3800, Accuracy: 2187/2500 (87%)\n",
            "\n",
            "Epoch 100/200\n",
            "Training: Average Loss: 0.4289, Accuracy: 40445/47500 (85%)\n",
            "Validation: Average Loss: 0.5729, Accuracy: 2046/2500 (82%)\n",
            "\n",
            "Epoch 101/200\n",
            "Training: Average Loss: 0.4359, Accuracy: 40354/47500 (85%)\n",
            "Validation: Average Loss: 0.4294, Accuracy: 2161/2500 (86%)\n",
            "\n",
            "Epoch 102/200\n",
            "Training: Average Loss: 0.4352, Accuracy: 40390/47500 (85%)\n",
            "Validation: Average Loss: 0.5518, Accuracy: 2057/2500 (82%)\n",
            "\n",
            "Epoch 103/200\n",
            "Training: Average Loss: 0.4321, Accuracy: 40439/47500 (85%)\n",
            "Validation: Average Loss: 0.4048, Accuracy: 2164/2500 (87%)\n",
            "\n",
            "Epoch 104/200\n",
            "Training: Average Loss: 0.4279, Accuracy: 40492/47500 (85%)\n",
            "Validation: Average Loss: 0.5545, Accuracy: 2073/2500 (83%)\n",
            "\n",
            "Epoch 105/200\n",
            "Training: Average Loss: 0.4330, Accuracy: 40230/47500 (85%)\n",
            "Validation: Average Loss: 0.4729, Accuracy: 2120/2500 (85%)\n",
            "\n",
            "Epoch 106/200\n",
            "Training: Average Loss: 0.4216, Accuracy: 40576/47500 (85%)\n",
            "Validation: Average Loss: 0.4372, Accuracy: 2143/2500 (86%)\n",
            "\n",
            "Epoch 107/200\n",
            "Training: Average Loss: 0.4134, Accuracy: 40577/47500 (85%)\n",
            "Validation: Average Loss: 0.3872, Accuracy: 2179/2500 (87%)\n",
            "\n",
            "Epoch 108/200\n",
            "Training: Average Loss: 0.4173, Accuracy: 40628/47500 (86%)\n",
            "Validation: Average Loss: 0.4706, Accuracy: 2120/2500 (85%)\n",
            "\n",
            "Epoch 109/200\n",
            "Training: Average Loss: 0.4220, Accuracy: 40579/47500 (85%)\n",
            "Validation: Average Loss: 0.5581, Accuracy: 2076/2500 (83%)\n",
            "\n",
            "Epoch 110/200\n",
            "Training: Average Loss: 0.4001, Accuracy: 40918/47500 (86%)\n",
            "Validation: Average Loss: 0.4024, Accuracy: 2132/2500 (85%)\n",
            "\n",
            "Epoch 111/200\n",
            "Training: Average Loss: 0.4023, Accuracy: 40834/47500 (86%)\n",
            "Validation: Average Loss: 0.4962, Accuracy: 2130/2500 (85%)\n",
            "\n",
            "Epoch 112/200\n",
            "Training: Average Loss: 0.4030, Accuracy: 40850/47500 (86%)\n",
            "Validation: Average Loss: 0.3803, Accuracy: 2179/2500 (87%)\n",
            "\n",
            "Epoch 113/200\n",
            "Training: Average Loss: 0.3960, Accuracy: 41039/47500 (86%)\n",
            "Validation: Average Loss: 0.3867, Accuracy: 2172/2500 (87%)\n",
            "\n",
            "Epoch 114/200\n",
            "Training: Average Loss: 0.3958, Accuracy: 41105/47500 (87%)\n",
            "Validation: Average Loss: 0.4067, Accuracy: 2152/2500 (86%)\n",
            "\n",
            "Epoch 115/200\n",
            "Training: Average Loss: 0.3886, Accuracy: 41097/47500 (87%)\n",
            "Validation: Average Loss: 0.4070, Accuracy: 2165/2500 (87%)\n",
            "\n",
            "Epoch 116/200\n",
            "Training: Average Loss: 0.3859, Accuracy: 41168/47500 (87%)\n",
            "Validation: Average Loss: 0.3247, Accuracy: 2227/2500 (89%)\n",
            "\n",
            "Epoch 117/200\n",
            "Training: Average Loss: 0.3869, Accuracy: 41082/47500 (86%)\n",
            "Validation: Average Loss: 0.3807, Accuracy: 2190/2500 (88%)\n",
            "\n",
            "Epoch 118/200\n",
            "Training: Average Loss: 0.3875, Accuracy: 41171/47500 (87%)\n",
            "Validation: Average Loss: 0.3521, Accuracy: 2202/2500 (88%)\n",
            "\n",
            "Epoch 119/200\n",
            "Training: Average Loss: 0.3733, Accuracy: 41301/47500 (87%)\n",
            "Validation: Average Loss: 0.4083, Accuracy: 2170/2500 (87%)\n",
            "\n",
            "Epoch 120/200\n",
            "Training: Average Loss: 0.3796, Accuracy: 41212/47500 (87%)\n",
            "Validation: Average Loss: 0.3521, Accuracy: 2190/2500 (88%)\n",
            "\n",
            "Epoch 121/200\n",
            "Training: Average Loss: 0.3670, Accuracy: 41482/47500 (87%)\n",
            "Validation: Average Loss: 0.3512, Accuracy: 2198/2500 (88%)\n",
            "\n",
            "Epoch 122/200\n",
            "Training: Average Loss: 0.3667, Accuracy: 41423/47500 (87%)\n",
            "Validation: Average Loss: 0.3801, Accuracy: 2185/2500 (87%)\n",
            "\n",
            "Epoch 123/200\n",
            "Training: Average Loss: 0.3615, Accuracy: 41485/47500 (87%)\n",
            "Validation: Average Loss: 0.3637, Accuracy: 2204/2500 (88%)\n",
            "\n",
            "Epoch 124/200\n",
            "Training: Average Loss: 0.3616, Accuracy: 41501/47500 (87%)\n",
            "Validation: Average Loss: 0.3731, Accuracy: 2186/2500 (87%)\n",
            "\n",
            "Epoch 125/200\n",
            "Training: Average Loss: 0.3555, Accuracy: 41668/47500 (88%)\n",
            "Validation: Average Loss: 0.3825, Accuracy: 2200/2500 (88%)\n",
            "\n",
            "Epoch 126/200\n",
            "Training: Average Loss: 0.3557, Accuracy: 41567/47500 (88%)\n",
            "Validation: Average Loss: 0.3849, Accuracy: 2172/2500 (87%)\n",
            "\n",
            "Epoch 127/200\n",
            "Training: Average Loss: 0.3573, Accuracy: 41562/47500 (87%)\n",
            "Validation: Average Loss: 0.3344, Accuracy: 2228/2500 (89%)\n",
            "\n",
            "Epoch 128/200\n",
            "Training: Average Loss: 0.3487, Accuracy: 41760/47500 (88%)\n",
            "Validation: Average Loss: 0.3207, Accuracy: 2238/2500 (90%)\n",
            "\n",
            "Epoch 129/200\n",
            "Training: Average Loss: 0.3327, Accuracy: 42076/47500 (89%)\n",
            "Validation: Average Loss: 0.3367, Accuracy: 2224/2500 (89%)\n",
            "\n",
            "Epoch 130/200\n",
            "Training: Average Loss: 0.3298, Accuracy: 42015/47500 (88%)\n",
            "Validation: Average Loss: 0.3793, Accuracy: 2190/2500 (88%)\n",
            "\n",
            "Epoch 131/200\n",
            "Training: Average Loss: 0.3340, Accuracy: 41955/47500 (88%)\n",
            "Validation: Average Loss: 0.4647, Accuracy: 2143/2500 (86%)\n",
            "\n",
            "Epoch 132/200\n",
            "Training: Average Loss: 0.3292, Accuracy: 42015/47500 (88%)\n",
            "Validation: Average Loss: 0.3909, Accuracy: 2184/2500 (87%)\n",
            "\n",
            "Epoch 133/200\n",
            "Training: Average Loss: 0.3310, Accuracy: 42036/47500 (88%)\n",
            "Validation: Average Loss: 0.3106, Accuracy: 2240/2500 (90%)\n",
            "\n",
            "Epoch 134/200\n",
            "Training: Average Loss: 0.3185, Accuracy: 42149/47500 (89%)\n",
            "Validation: Average Loss: 0.3614, Accuracy: 2211/2500 (88%)\n",
            "\n",
            "Epoch 135/200\n",
            "Training: Average Loss: 0.3163, Accuracy: 42216/47500 (89%)\n",
            "Validation: Average Loss: 0.3429, Accuracy: 2219/2500 (89%)\n",
            "\n",
            "Epoch 136/200\n",
            "Training: Average Loss: 0.3129, Accuracy: 42267/47500 (89%)\n",
            "Validation: Average Loss: 0.3550, Accuracy: 2213/2500 (89%)\n",
            "\n",
            "Epoch 137/200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "test_images, test_labels = load_cifar10_batch('/content/test_batch')\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "test_images_tensor = torch.stack([transform_test(Image.fromarray(img)) for img in test_images])\n",
        "test_labels_tensor = torch.tensor(test_labels)\n",
        "\n",
        "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100.0 * correct / total\n",
        "print(f'Accuracy on the test set: {test_accuracy}%')"
      ],
      "metadata": {
        "id": "_zl1iuu23w3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "\n",
        "transform_test = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def load_pickle_file(filename):\n",
        "    with open(filename, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "    return data\n",
        "\n",
        "unlabeled_test_data = load_pickle_file('/content/cifar_test_nolabels.pkl')\n",
        "num_images = unlabeled_test_data[b'data'].shape[0]\n",
        "test_images = unlabeled_test_data[b'data'].reshape((num_images, 3, 32, 32)).transpose((0, 2, 3, 1))\n",
        "\n",
        "transformed_images = [transform_test(Image.fromarray(img)) for img in test_images]\n",
        "\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, img in enumerate(transformed_images):\n",
        "        img = img.unsqueeze(0).to(device)\n",
        "        outputs = model(img)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predictions.append((i, predicted.item()))\n",
        "\n",
        "df_predictions = pd.DataFrame(predictions, columns=[\"ID\", \"Labels\"])\n",
        "df_predictions.to_csv('/content/predicted_labels.csv', index=False)\n"
      ],
      "metadata": {
        "id": "gYOeq8o_9VYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j0HzBBCcZo4R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}